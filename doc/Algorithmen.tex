% Grundeinstellungen
\documentclass[
	11pt,
	notitlepage,
	oneside
]{scrartcl}
\KOMAoptions{
	parskip=half
}
\usepackage{scrhack}
% Encoding
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Silbentrennung Deutsch
\usepackage[ngerman]{babel}
\usepackage{blindtext}
\usepackage{hyphenat}

\usepackage[linesnumbered]{algorithm2e}
\title{Tweegion - Algorithmen}
\author{Johannes Gontrum, Matthias Wegel, Steve Wendler}
\begin{document}
\section{Main-Algorithm}

\begin{algorithm}[H]
 \SetAlgoLined
 \KwData{\\
	$WV_0$: bestehende, normalisierte Liste von Wortvektoren\\ 
	$Tweets$: Liste von Tweets\\ 
	$Stopwords$: Liste von Stoppwörtern \\ $ $}
 \KwResult{\\$WV_{1}$: verbesserte, normalisierte Liste von Wortvektoren\\ $ $}
 $WV_{1} \gets\emptyset $\; 
\ForEach{\label{alg:goto}Tweet in Tweets}{
 $V_{Tweet} \gets (0,0,0,0,0,0,0)$\;
 \ForAll{Token in Tweet}{
  \If{Token $\notin$ Stopwords}{
     $V_{Tweet}  \gets V_{Tweet} + WV_0(Token)$\;
   }
}
 \ForAll{Token in Tweet}{
  \If{Token $\notin$ Stopwords}{
     $WV_{1}(Token)  \gets WV_{1}(Token) + V_{Tweet}$\;
   }
}
}
 \ForEach{$V_{Word}$ in $WV_{1}$}{
$V_{Word}$ $\gets$ normalize($V_{Word}$)\;
}
\eIf{difference($WV_0$, $WV_1$) < significance level}{
$WV_0 \leftarrow WV_1$\;
Goto Line \ref{alg:goto}\;
}{
\Return $WV_1$\;
}
\caption{Tweegion Main-Algorithm}
\end{algorithm}

\section{Geo-Algorithm}
\begin{algorithm}[H]
 \SetAlgoLined
 \KwData{\\
	$Tweets$: Liste von Tweets mit Geo-Informationen\\ 
	$Stopwords$: Liste von Stoppwörtern \\ $ $}
 \KwResult{\\$WV$: normalisierte Liste von Tokenvektoren\\ $ $}
 $WV \gets\emptyset $\; 
\ForEach{\label{alg:goto}Tweet in Tweets}{
$n \gets classify(Tweet)$\;
 $V_{Tweet} \gets createVector(n)$\;
 \ForAll{Token in Tweet}{
  \If{Token $\notin$ Stopwords}{
     $WV(Token) \gets WV(Token) + V_{Tweet}$\;
   }
}
}
 \ForEach{$V_{Word}$ in $WV$}{
$V_{Word}$ $\gets$ normalize($V_{Word}$)\;
}
\Return $WV_1$\;

\caption{Tweegion Geo-Algorithm}
\end{algorithm}

\end{document}